# LangChain RAG Playground üõù

## Introduction
Streamlit application that enables users to upload a pdf file and chat with an LLM for performing document analysis in a playground environment. 
Compare the performance of LLMs across endpoint providers to find the best possible configuration for your speed, latency and cost requirements using the dynamic routing feature.
Play intuitively tuning the model hyperparameters as temperature, chunk size, chunk overlap or try the model with/without conversational capabilities. 

You find more model/provider information in the [Unify benchmark interface](https://unify.ai/hub).

## Quick Demo
-ebeded video-

## Usage:
1. Go to the application: https://unify-rag-playground.streamlit.app/
2. Input your Unify API Key. If you don‚Äôt have one yet, log in to the [console](https://console.unify.ai/) to get yours.
3. Select the Model and endpoint provider of your choice from the drop down. You can find both model and provider information in the benchmark interface.
4. Upload your document(s) and click the Submit button
5. Play!

## Repository and Deployment
Repository is located here https://github.com/Anteemony/RAG-Playground 

To run the application locally:
1. Clone the repo in your local machine
2. Create a virtual envirnoment and install requirements.txt
3. Run rag_script.py from Streamlit module ( Python -m run streamlit rag_script.py)

## Contributors

| Name | GitHub Profile |
|------|----------------|
| Anthony Okonneh | [AO](https://github.com/Anteemony) |
| Oscar Arroyo Vega | [OAV](https://github.com/OscarArroyoVega) |
| Martin Oywa | [Martin Oywa](https://github.com/martinoywa) |

